---
title: "Validations by simulation"
date: "`r Sys.Date()`"
output: word_document
---

It is assumed that `analyze_slimm_t2d_omics.Rmd` was already run, so `ezlimma` and `Hitman` have been installed. Then, installation time is under one minute. Some of this code took too long on a desktop, so was run on a server, as described below.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include=FALSE)
options(digits=3, stringsAsFactors=FALSE)
library(ezlimma)
library(Hitman)
library(Matrix)

library(dplyr)
library(reshape2)
library(writexl)
source("R/melt_sim_tab.R")
```

We validate the ability of `hitman` to control its false positive rate (*size*) and have a high rate of detecting true positives (*power*) via simulations, where we know the truth.

We simulate our mediation methods and compare them against the benchmark simulation of several mediation methods from Barfield et al. (2017), Table 1, for N=50.

```{r}
nsim <- 10**4
nsamp <- 50
t1 <- 0.59
```


## Validating our simulations with joint significance test


To validate that our function provides results consistent with the simulations in Barfield et al. (2017), we compared Barfield et al.'s simulations with the joint significance test to our simulations with the joint significance test.

We implemented the joint significance test in R. We first tested that this function gave the same results as another implemention of this test in R, the function `mdt_simple` in package `JSmediation`. Here, we validate that our implementation matches Barfield et al. (2017) Table 1. This calculation takes ~5 min on my desktop PC. 

```{r, eval=FALSE}
# also test js for small samples
Joint <- Hitman:::joint_signif_mediation
prop.sig.js <- Hitman:::sim_barfield(med.fnm = "Joint", b1t2.v=c(0, 0.14, 0.39), nsim = nsim, nsamp=nsamp, t1=t1)
write.csv(prop.sig.js, paste0("./validation/sim_jointsig_nsamp", nsamp, "_nsim", nsim, "_t1", t1, ".csv"), na="")
```


## Hitman


This calculation takes ~30 min on my desktop PC. Our simulation results are at [sim_hitman_nsamp50_nsim10000.csv](./validation/sim_hitman_nsamp50_nsim10000.csv).

```{r, eval=FALSE}
# t2=0.39; b1=0 < 0.05 with ngenes=2 & their SD in sim_barfield = 2
# nsamp=50, so limited effect of limma
# tried with one of b1t2 < 0, and Hitman had even better control of its false pos rate
# tried w/ alpha=0.7, and hitman previously did not control false pos rate, but does after modification
(prop.sig.hit <- Hitman:::sim_barfield(med.fnm = "hitman", b1t2.v=c(0, 0.14, 0.39), nsim = nsim, ngene=9, nsamp = nsamp, t1=t1))
write.csv(prop.sig.hit, paste0("./validation/sim_hitman_nsamp", nsamp, "_nsim", nsim, "_t1", t1, ".csv"), na="")
```

## Counterfactual / potential outcomes

From `mediation` package. This was quite slow because it resamples to estimate null distribution, so we ran it with 
R scripts representing the below on the Linux cluster, called "O2", at Harvard Medical School for nsim=1000.

```{r, eval=FALSE}
nsim=1000
ezmed <- Hitman:::ezmediate
prop.sig.med <- Hitman:::sim_barfield(med.fnm = "ezmed", b1t2.v=c(0, 0.14, 0.39), nsim = nsim, sims=nsim, t1=t1)
write.csv(prop.sig.med, paste0("./validation/sim_mediate_nsamp50_nsim", nsim, "_nperm", nsim, "_t1", t1, ".csv"), na="")
```

## Compile tables

Compile Barfield table and output from our simulations into one matrix for N=50.

```{r, eval=FALSE}
nsamp <- 50
# barfield <- read.csv("validation/barfield2017_Table1_N50.csv")
# rownames(barfield) <- paste0(barfield[, 1], barfield[, 2])
hit <- melt_sim_tab(read.csv("validation/sim_hitman_nsamp50_nsim10000_t10.59.csv"), nm="Hitman")
rownames(hit) <- paste0(hit[, 1], hit[, 2])
js <- melt_sim_tab(read.csv("validation/sim_jointsig_nsamp50_nsim10000_t10.59.csv"), nm="joint")
rownames(js) <- paste0(js[, 1], js[, 2])
med <- melt_sim_tab(read.csv("validation/sim_mediate_nsamp50_nsim1000_nperm1000_t10.59.csv"), nm="mediate")
rownames(med) <- paste0(med[, 1], med[, 2])

stopifnot(rownames(hit)==rownames(med), rownames(hit)==rownames(js))
comb.mat <- data.matrix(data.frame(hit, js[, -(1:2), drop=FALSE], 
                                   med[, -(1:2), drop=FALSE]))
comb.mat <- comb.mat[order(-rowSums(comb.mat[, 1:2]==0), rowSums(comb.mat[, 1:2])), ]
# write_xlsx(x=as.data.frame(comb.mat), "validation/combined_n50_sim_tab.xlsx")
write.csv(x = comb.mat, file = "validation/combined_n50_sim_tab.csv", row.names = FALSE)
```

Test significance of difference in power.

```{r t.test, include=TRUE}
hit.0.39.prop <- nsim*signif(as.numeric(data.frame(comb.mat) %>% filter(b1==0.39, t2==0.39) %>% select("Hitman")), 5)
hit.0.14.prop <- nsim*signif(as.numeric(data.frame(comb.mat) %>% filter(b1==0.14, t2==0.14) %>% select("Hitman")), 5)

other.0.39.prop <- nsim*signif(as.numeric(data.frame(comb.mat) %>% filter(b1==0.39, t2==0.39) %>% select("mediate")), 5)
other.0.14.prop <- nsim*signif(as.numeric(data.frame(comb.mat) %>% filter(b1==0.14, t2==0.14) %>% select("joint")), 5)

tt.39 <- t.test(x=rep(1:0, c(hit.0.39.prop, nsim-hit.0.39.prop)),
                y=rep(1:0, nsim*c(other.0.39.prop, nsim-other.0.39.prop)),
                var.equal = TRUE)
print(tt.39)

tt.14 <- t.test(x=rep(1:0, c(hit.0.14.prop, nsim-hit.0.14.prop)),
                y=rep(1:0, nsim*c(other.0.14.prop, nsim-other.0.14.prop)),
                var.equal = TRUE)
print(tt.14)
```

# References
Barfield R, Shen J, Just AC, Vokonas PS, Schwartz J, Baccarelli AA, VanderWeele TJ, Lin X. Testing for the indirect effect under the null for genome-wide mediation analyses. Genet Epidemiol. 2017 Dec;41(8):824-833.